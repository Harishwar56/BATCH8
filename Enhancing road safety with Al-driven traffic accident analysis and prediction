from  google.colab  import  files
uploaded = files.upload()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM,Dense
from sklearn.preprocessing import MinMaxScaler
df = pd.read_csv("traffic.csv")
print(df.head())
print(df.info())
print(df.describe())
try:
    # First try with known format
    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d-%m-%Y %H.%M')
except (ValueError, pd.errors.ParserError):
    print("Known format failed, trying automatic parsing...")
    df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')

# Drop rows where datetime conversion failed
df.dropna(subset=['DateTime'], inplace=True)

# Set datetime index and isolate relevant column
df.set_index('DateTime', inplace=True)

# Ensure the correct column name is used
if 'Traffic_Volume' in df.columns:
    df = df[['Traffic_Volume']]
else:
    print("Column 'Traffic_Volume' not found. Available columns:", df.columns)

# Scaling
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df)

# Sequence creation
X = []
y = []
time_step = 60
for i in range(time_step, len(scaled_data)):
    X.append(scaled_data[i-time_step:i])
    y.append(scaled_data[i])

X, y = np.array(X),np.array(y)
